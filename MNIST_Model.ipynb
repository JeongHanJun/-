{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Model.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3beyn/pK7oJuekvxyg6it",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/-/blob/master/MNIST_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFwnpEAZ_ZEr"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.optim as optim\n",
        " \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class NN(nn.Module):    #NN = Neural Network = 신경망\n",
        "    def __init__(self, num_classes = 10):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 1,1)\n",
        "        self.Maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "      \n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.conv7 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "\n",
        "\n",
        "        self.conv8 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.conv9 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "        self.conv11 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(512, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, self.num_classes)\n",
        "\n",
        "\n",
        "        # self.dropout1 = nn.Dropout2d(0, 25)\n",
        "        # self.dropout2 = nn.Dropout2d(0, 16)\n",
        "        # self.fc1 = nn.Linear(9216, 128)\n",
        "        # self.fc2 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):           \n",
        "        # x = self.conv1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.conv2(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.max_pool2d(x, 2)\n",
        "        # x = self.dropout1(x)\n",
        "        # x = torch.flatten(x, 1)\n",
        "        # x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.dropout2(x)\n",
        "        # x = self.fc2(x)\n",
        "        # output = F.log_softmax(x, dim = 1)\n",
        "        # return output\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv7(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv9(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv10(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "\n",
        "        x = self.conv11(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.shape)\n",
        "        # return x\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim = 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "        \n",
        "net= NN()\n",
        "data = torch.ones(1, 3, 32, 32)\n",
        "net(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEHXX-txAIXI"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.optim as optim\n",
        " \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class NN(nn.Module):    #NN = Neural Network = 신경망\n",
        "    def __init__(self, num_classes = 10):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 1,1)\n",
        "        self.Maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "      \n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.conv7 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "\n",
        "\n",
        "        self.conv8 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.conv9 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "        self.conv11 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(25088, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, self.num_classes)\n",
        "\n",
        "\n",
        "        # self.dropout1 = nn.Dropout2d(0, 25)\n",
        "        # self.dropout2 = nn.Dropout2d(0, 16)\n",
        "        # self.fc1 = nn.Linear(9216, 128)\n",
        "        # self.fc2 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):           \n",
        "        # x = self.conv1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.conv2(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.max_pool2d(x, 2)\n",
        "        # x = self.dropout1(x)\n",
        "        # x = torch.flatten(x, 1)\n",
        "        # x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.dropout2(x)\n",
        "        # x = self.fc2(x)\n",
        "        # output = F.log_softmax(x, dim = 1)\n",
        "        # return output\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv7(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv9(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv10(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "\n",
        "        x = self.conv11(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim = 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "        \n",
        "net= NN()\n",
        " \n",
        "learning_rate = 0.01    # 학습률 0.01로 임의 지정 \n",
        "batch_size =100         # batch 는 한번에 처리하는 사진의 수 batch_size = 100 이면 한번에 100장씩 처리한다는 뜻\n",
        " \n",
        "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum= 0.9)  # 확률적 경사 하강범 ( momentom = 양수의 실수값, 가속도)  w += lr * gradient\n",
        "criterion= nn.NLLLoss()         # NLLlose log_softMax 에 대한 결과값 (교차 엔트로피 손실 연산?)\n",
        " \n",
        "train_set = torchvision.datasets.FashionMNIST(  # data set을 받아옴\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        " \n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)    # 위의 data를 받아옴\n",
        " \n",
        "epochs = 5  # epoch는 전체 data set에 대해 몇번 학습(forward)을 돌릴것인가\n",
        " \n",
        "pd_results= []  # list형태로 출력\n",
        " \n",
        "for epoch in range(epochs): # 전체학습을 epochs 만큼 반복\n",
        "    batch_idx = 0           # 변수 초기화\n",
        "    tot_num = 0\n",
        "    correct_num = 0\n",
        "    for batch in loader:\n",
        "        batch_idx += 1  # 1개씩 늘리면서 진행\n",
        " \n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        " \n",
        "        # images = images.view(-1, 28*28) # view(-1, size) 에서 왜 -1인가? -> (batch_size, 784)\n",
        "        \n",
        "        optimizer.zero_grad()   # gradient를 0 으로 해야 반복할때 오버래핑이 안생김\n",
        " \n",
        "        net_out= net(images)\n",
        " \n",
        "        loss = criterion(net_out, labels)   # 손실률\n",
        " \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "        for i in range(len(labels)):\n",
        "            tot_num += 1\n",
        "            pred = torch.max(net_out[i], 0)[1]\n",
        "            correct_num += pred.eq(labels[i]).sum()\n",
        "        \n",
        "        if batch_idx % 100 == 0:                                # data 양이 많으니 100배수 에서 출력\n",
        "            results = OrderedDict()\n",
        "            results['epoch'] = epoch\n",
        "            results['batch_idx'] = batch_idx\n",
        "            results['loss'] = loss.item()\n",
        "            results['accuracy'] = 100.*correct_num.item()/tot_num\n",
        "            pd_results.append(results)\n",
        "            df = pd.DataFrame.from_dict(pd_results, orient = 'columns')\n",
        " \n",
        "            clear_output(wait = True)\n",
        "            display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqs9wc6x2PMP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}