{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqaFt+twcGkSord2VfSrUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/-/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9fL1UxVTU5t",
        "outputId": "0b2b8692-3a59-4661-c266-3deb0df0eea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.optim as optim\n",
        " \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        " \n",
        "class NN(nn.Module):    #NN = Neural Network = 신경망\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=28*28, out_features=200)   # MNIST 그림의 크기 28x28 , 200개의 노드  = Input Layer\n",
        "        self.fc2 = nn.Linear(in_features=200, out_features=200)     # First Layer -> Second Layer\n",
        "        self.fc3 = nn.Linear(in_features=200, out_features=10)      # Second Layer -> Output Layer\n",
        "        \n",
        "    def forward(self, x):           # 학습 진행 방향\n",
        "        x = F.relu(self.fc1(x))     # fc1 ->\n",
        "        x = F.relu(self.fc2(x))     # fc1 -> fc2 ->\n",
        "        x = self.fc3(x)             # fc1 -> fc2 -> fc3         relu max(0, x) , sigmoid는 0과 1 사이값 \n",
        "        return F.log_softmax(x) \n",
        "        '''\n",
        "            활성화 함수 relu 와 sigmoid\n",
        " \n",
        "            relu 는 간단히 max(0,x) <0 이면 0출력 , >0 이면 그 값 출력\n",
        " \n",
        "            sigmoid = 1 / (1+e^-x)  기함수형태 , (0,1/2) 대칭 , tanh 형태\n",
        "            최소 제곱법에 대해 분산, 표준편차를 알수 있음\n",
        "             0 <= 확률 P <= 1 에 대해  y = f(x1.x2.x3....) 변수가 많은 식에 대한 y의 값은 무의미한 값을 가지게 되는 경우가 많다.\n",
        "             (종속변수 y에 대해 선형모델을 적용했을때 최소제곱직선 기준 떨어진 데이터들이 많으므로 무의미하다.)\n",
        "             직선 형태를 선형 로그 (tanh 형태)로 변형해서 데이터들의 오차를 줄이려는 것\n",
        "            torch.nn 의 log_softmax 는 신경망 말단 노드들의 결과값을 확률개념으로 해석하기 위해 log를 취한것 \n",
        "            ( p / 1-p ) -(log , 정의영ㄱ/치역확인)> (mx+b) -(실수 전범위 이므로 의미 있는 선형 모델 , p에 대해 정리하면)> (1/1+e^-x)\n",
        " \n",
        "            hidden layer 즉 학습과정에서 relu를 쓰고 마지막 output에서는 sigmoid를 쓰는게 효과적\n",
        "        '''\n",
        " \n",
        "net= NN()\n",
        " \n",
        "learning_rate = 0.01    # 학습률 0.01로 임의 지정 \n",
        "batch_size =100         # batch 는 한번에 처리하는 사진의 수 batch_size = 100 이면 한번에 100장씩 처리한다는 뜻\n",
        " \n",
        "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum= 0.9)  # 확률적 경사 하강범 ( momentom = 양수의 실수값, 가속도)  w += lr * gradient\n",
        "criterion= nn.NLLLoss()         # NLLlose log_softMax 에 대한 결과값 (교차 엔트로피 손실 연산?)\n",
        " \n",
        "train_set = torchvision.datasets.FashionMNIST(  # data set을 받아옴\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        " \n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)    # 위의 data를 받아옴\n",
        " \n",
        "epochs = 5  # epoch는 전체 data set에 대해 몇번 학습(forward)을 돌릴것인가\n",
        " \n",
        "pd_results= []  # list형태로 출력\n",
        " \n",
        "for epoch in range(epochs): # 전체학습을 epochs 만큼 반복\n",
        "    batch_idx = 0           # 변수 초기화\n",
        "    tot_num = 0\n",
        "    correct_num = 0\n",
        "    for batch in loader:\n",
        "        batch_idx += 1  # 1개씩 늘리면서 진행\n",
        " \n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        " \n",
        "        images = images.view(-1, 28*28) # view(-1, size) 에서 왜 -1인가? -> (batch_size, 784)\n",
        "        \n",
        "        optimizer.zero_grad()   # gradient를 0 으로 해야 반복할때 오버래핑이 안생김\n",
        " \n",
        "        net_out= net(images)\n",
        " \n",
        "        loss = criterion(net_out, labels)   # 손실률\n",
        " \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "        for i in range(len(labels)):\n",
        "            tot_num += 1\n",
        "            pred = torch.max(net_out[i], 0)[1]\n",
        "            correct_num += pred.eq(labels[i]).sum()\n",
        "        \n",
        "        if batch_idx % 100 == 0:                                # data 양이 많으니 100배수 에서 출력\n",
        "            results = OrderedDict()\n",
        "            results['epoch'] = epoch\n",
        "            results['batch_idx'] = batch_idx\n",
        "            results['loss'] = loss.item()\n",
        "            results['accuracy'] = 100.*correct_num.item()/tot_num\n",
        "            pd_results.append(results)\n",
        "            df = pd.DataFrame.from_dict(pd_results, orient = 'columns')\n",
        " \n",
        "            clear_output(wait = True)\n",
        "            display(df)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>batch_idx</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.948239</td>\n",
              "      <td>48.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>0.905982</td>\n",
              "      <td>59.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>0.582087</td>\n",
              "      <td>65.663333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>400</td>\n",
              "      <td>0.559721</td>\n",
              "      <td>69.357500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>500</td>\n",
              "      <td>0.632570</td>\n",
              "      <td>71.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>600</td>\n",
              "      <td>0.496619</td>\n",
              "      <td>73.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.404887</td>\n",
              "      <td>82.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>0.510672</td>\n",
              "      <td>82.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>300</td>\n",
              "      <td>0.493226</td>\n",
              "      <td>83.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>400</td>\n",
              "      <td>0.485011</td>\n",
              "      <td>83.362500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>0.581083</td>\n",
              "      <td>83.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>600</td>\n",
              "      <td>0.397340</td>\n",
              "      <td>83.751667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.336039</td>\n",
              "      <td>85.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>200</td>\n",
              "      <td>0.431163</td>\n",
              "      <td>85.165000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>300</td>\n",
              "      <td>0.407044</td>\n",
              "      <td>85.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>400</td>\n",
              "      <td>0.437507</td>\n",
              "      <td>85.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>0.551865</td>\n",
              "      <td>85.532000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>600</td>\n",
              "      <td>0.342976</td>\n",
              "      <td>85.561667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0.317766</td>\n",
              "      <td>86.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "      <td>0.396193</td>\n",
              "      <td>86.295000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3</td>\n",
              "      <td>300</td>\n",
              "      <td>0.367790</td>\n",
              "      <td>86.306667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3</td>\n",
              "      <td>400</td>\n",
              "      <td>0.413882</td>\n",
              "      <td>86.465000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3</td>\n",
              "      <td>500</td>\n",
              "      <td>0.523817</td>\n",
              "      <td>86.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3</td>\n",
              "      <td>600</td>\n",
              "      <td>0.311282</td>\n",
              "      <td>86.598333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>0.291005</td>\n",
              "      <td>87.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4</td>\n",
              "      <td>200</td>\n",
              "      <td>0.372694</td>\n",
              "      <td>87.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4</td>\n",
              "      <td>300</td>\n",
              "      <td>0.335013</td>\n",
              "      <td>87.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4</td>\n",
              "      <td>400</td>\n",
              "      <td>0.402820</td>\n",
              "      <td>87.255000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>4</td>\n",
              "      <td>500</td>\n",
              "      <td>0.491892</td>\n",
              "      <td>87.344000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4</td>\n",
              "      <td>600</td>\n",
              "      <td>0.285556</td>\n",
              "      <td>87.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch  batch_idx      loss   accuracy\n",
              "0       0        100  0.948239  48.480000\n",
              "1       0        200  0.905982  59.920000\n",
              "2       0        300  0.582087  65.663333\n",
              "3       0        400  0.559721  69.357500\n",
              "4       0        500  0.632570  71.798000\n",
              "5       0        600  0.496619  73.315000\n",
              "6       1        100  0.404887  82.540000\n",
              "7       1        200  0.510672  82.765000\n",
              "8       1        300  0.493226  83.030000\n",
              "9       1        400  0.485011  83.362500\n",
              "10      1        500  0.581083  83.592000\n",
              "11      1        600  0.397340  83.751667\n",
              "12      2        100  0.336039  85.380000\n",
              "13      2        200  0.431163  85.165000\n",
              "14      2        300  0.407044  85.200000\n",
              "15      2        400  0.437507  85.437500\n",
              "16      2        500  0.551865  85.532000\n",
              "17      2        600  0.342976  85.561667\n",
              "18      3        100  0.317766  86.580000\n",
              "19      3        200  0.396193  86.295000\n",
              "20      3        300  0.367790  86.306667\n",
              "21      3        400  0.413882  86.465000\n",
              "22      3        500  0.523817  86.572000\n",
              "23      3        600  0.311282  86.598333\n",
              "24      4        100  0.291005  87.290000\n",
              "25      4        200  0.372694  87.130000\n",
              "26      4        300  0.335013  87.100000\n",
              "27      4        400  0.402820  87.255000\n",
              "28      4        500  0.491892  87.344000\n",
              "29      4        600  0.285556  87.360000"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1yME3G3MQqG"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRlZTexMS6m"
      },
      "source": [
        "a = np.ones([28,28])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnetSJmLMZYP",
        "outputId": "c734d11d-c4c4-4dad-af9d-60b0544d6d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvQxHuC7Mcwv",
        "outputId": "9b415c40-65c0-4e08-dbf4-5ab3b5d85818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.reshape(-1, 28*28).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HvCSdcVMkH5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}